# ğŸ§  Classification dâ€™images avec un rÃ©seau neuronal dense (DNN)

##  Objectif
Construire un modÃ¨le DNN simple pour classer des images de vÃªtements (Fashion MNIST) en 10 catÃ©gories. Ce prototype vise Ã  valider un pipeline IA complet avant dâ€™envisager des architectures plus avancÃ©es.
##  DonnÃ©es
- Images 28x28 en niveaux de gris
- 10 classes (vÃªtements)
- Normalisation des pixels (valeurs entre 0 et 1)
- Labels entiers (0 Ã  9)
##  ModÃ¨le
- Architecture : Flatten â†’ Dense(128, ReLU) â†’ Dense(10, Softmax)
- Compilation : Optimiseur Adam, perte `sparse_categorical_crossentropy`, mÃ©trique `accuracy`
##  EntraÃ®nement
- 15 Ã©poques avec validation split (20%)
- Callback EarlyStopping pour Ã©viter le surentraÃ®nement
- Sauvegarde du modÃ¨le
##  RÃ©sultats
- PrÃ©cision test : 87.91%
- Perte test : 0.3471
- Visualisation des courbes de prÃ©cision et de perte avec Matplotlib
##  HyperparamÃ¨tres
- Neurones : 128
- Activation : ReLU
- Optimiseur : Adam
- Perte : sparse categorical crossentropy
- Ã‰poques : 15
- Validation : 20%
- Callback : EarlyStopping
## Visualisation des performances
Deux graphiques ont Ã©tÃ© tracÃ©s pour suivre lâ€™Ã©volution du modÃ¨le pendant lâ€™entraÃ®nement :
    Courbe de prÃ©cision : montre lâ€™Ã©volution de la prÃ©cision sur les donnÃ©es dâ€™entraÃ®nement et de validation Ã  chaque Ã©poque. Cela permet de vÃ©rifier si le modÃ¨le apprend correctement et sâ€™il gÃ©nÃ©ralise bien.
    Courbe de perte : indique la diminution de lâ€™erreur (loss) au fil des Ã©poques. Une perte qui diminue rÃ©guliÃ¨rement est signe dâ€™un bon apprentissage.
Ces visualisations aident Ã  dÃ©tecter un Ã©ventuel surentraÃ®nement (overfitting) ou sous-apprentissage.
##  Fonction de perte
 Choix de la fonction de perte :
  -sparse_categorical_crossentropy est utilisÃ©e lorsque les labels sont des entiers (ex. : 0, 1, 2â€¦). Elle est simple Ã  implÃ©menter et Ã©vite de transformer les labels.
  -categorical_crossentropy est utilisÃ©e quand les labels sont encodÃ©s en one-hot (ex. : [0, 0, 1, 0, 0â€¦]). Elle nÃ©cessite une Ã©tape de prÃ©traitement supplÃ©mentaire.

Dans ce projet, les labels sont dÃ©jÃ  sous forme dâ€™entiers, donc sparse_categorical_crossentropy est le choix le plus adaptÃ©.
##  Conclusion
Le modÃ¨le rÃ©pond aux exigences du brief : il est simple, reproductible, performant (>80%) et constitue une base solide pour des modÃ¨les plus avancÃ©s.
